{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from anime_face_generator.config import PROCESSED_DATA_DIR, RAW_DATA_DIR, MODELS_DIR\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64, 64)\n",
    "batch_nbr = 16\n",
    "channels = 3\n",
    "\n",
    "img_dim=img_size[0] * img_size[1] * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=img_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(10, fill=(255, 255, 255)),\n",
    "#     torchvision.transforms.RandomResizedCrop(size=img_size, scale=(0.8, 1.0)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    # torchvision.transforms.Lambda(lambda x: x.view(-1))  #flattening\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=PROCESSED_DATA_DIR, transform=transformers, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gen = torch.Generator().manual_seed(142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 600  # total diffusion steps\n",
    "\n",
    "# Linear noise schedule\n",
    "beta = torch.linspace(1e-4, 0.02, T).to(device)         # β_t ∈ (0.0001, 0.02)\n",
    "alpha = 1. - beta                           # α_t = 1 - β_t\n",
    "alpha_bar = torch.cumprod(alpha, dim=0)     # \\bar{α}_t = product of α_1 to α_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Time Embedding Layer (Sinusoidal)\n",
    "# -----------------------------------\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(\n",
    "            torch.arange(half_dim, device=t.device) * -(np.log(10000) / (half_dim - 1))\n",
    "        )\n",
    "        emb = t[:, None] * emb[None, :]  # (B, half_dim)\n",
    "        return torch.cat([emb.sin(), emb.cos()], dim=-1)  # (B, dim)\n",
    "\n",
    "    \n",
    "# -----------------------------------\n",
    "# Basic Conv Block with Time Conditioning\n",
    "# -----------------------------------\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.conv1(x)\n",
    "        # Add time embedding: reshape to (B, C, 1, 1)\n",
    "        h += self.time_mlp(t_emb)[:, :, None, None]\n",
    "        h = nn.ReLU()(h)\n",
    "        h = self.conv2(h)\n",
    "        return h\n",
    "\n",
    "# -----------------------------------\n",
    "# U-Net for DDPM\n",
    "# -----------------------------------\n",
    "class UNet_DDPM(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=3, time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.time_embedding = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Down path\n",
    "        self.down1 = Block(in_ch, 64, time_emb_dim)\n",
    "        self.down2 = Block(64, 128, time_emb_dim)\n",
    "        self.down3 = Block(128, 256, time_emb_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bot = Block(256, 256, time_emb_dim)\n",
    "\n",
    "        # Up path\n",
    "        self.up3 = Block(256 + 256, 128, time_emb_dim)\n",
    "        self.up2 = Block(128 + 128, 64, time_emb_dim)\n",
    "        self.up1 = Block(64 + 64, out_ch, time_emb_dim)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_embedding(t)\n",
    "\n",
    "        # Down\n",
    "        x1 = self.down1(x, t_emb)\n",
    "        x2 = self.down2(self.pool(x1), t_emb)\n",
    "        x3 = self.down3(self.pool(x2), t_emb)\n",
    "\n",
    "        # Bottleneck\n",
    "        x4 = self.bot(self.pool(x3), t_emb)\n",
    "\n",
    "        # Up\n",
    "        x = self.upsample(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.up3(x, t_emb)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.up2(x, t_emb)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.up1(x, t_emb)\n",
    "\n",
    "        return x\n",
    "\n",
    "def q_sample(x0, t, noise=None): # add noise | forward pass | q(x_t | x_t-1)\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x0).to(device)\n",
    "    \n",
    "    sqrt_alpha_bar = alpha_bar[t].sqrt().view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha_bar = (1 - alpha_bar[t]).sqrt().view(-1, 1, 1, 1)\n",
    "    \n",
    "    return sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise # <= x_t \n",
    "\n",
    "def get_loss(model, x0, t=None):\n",
    "    B = x0.shape[0]\n",
    "    if t is None:\n",
    "        t = torch.randint(0, T, (B,), device=x0.device).long()\n",
    "    noise = torch.randn_like(x0).to(device)\n",
    "    x_t = q_sample(x0, t, noise).to(device)                       # q(x_t | x_t-1)\n",
    "    pred_noise = model(x_t.to(device), t.to(device)).to(device)   # ε_θ(x_t, t) -->  time is embeded instead\n",
    "    return nn.MSELoss()(pred_noise, noise), pred_noise, x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_DDPM().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = tdata.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_nbr,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 80\n",
    "size = len(dataloader.dataset)\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"--------------------------------------------- EPOCH \" + str(epoch) + \"------------------------------------\")\n",
    "    for batch, (x0_batch, _) in enumerate(dataloader):  # assume x0_batch ∈ [B, 1, 28, 28]\n",
    "        x0_batch = x0_batch.to(device)\n",
    "        t = torch.randint(0, T, (x0_batch.shape[0],), device=x0_batch.device).long()\n",
    "        loss, pred_noise, x_t = get_loss(model, x0_batch, t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if batch % (16 * 100) == 0:\n",
    "            loss_val, current = loss.item(), batch * batch_nbr + len(x0_batch)\n",
    "            print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\">>>>>>>>timestep in first x in the batch: \", t[0])\n",
    "    \n",
    "            # Visualize one sample\n",
    "            idx = 0  # you can change which sample in the batch to preview\n",
    "            img = x0_batch[idx].detach().cpu()\n",
    "            pred = pred_noise[idx].detach().cpu()\n",
    "            xt = x_t[idx].detach().cpu()\n",
    "            t_0 = t[idx].detach().cpu()\n",
    "    \n",
    "            # Option 1: show predicted noise\n",
    "            plt.figure(figsize=(6, 2))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(np.clip((img.permute(1, 2, 0) + 1) / 2, 0, 1))\n",
    "            plt.title(\"original input\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(np.clip((xt.permute(1, 2, 0) + 1) / 2, 0, 1))\n",
    "            plt.title(\"noised original\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            beta_t = beta[t_0].view(-1, 1, 1, 1)\n",
    "            sqrt_alpha_t = alpha[t_0].sqrt().view(-1, 1, 1, 1)\n",
    "            sqrt_one_minus_alpha_bar_t = (1 - alpha_bar[t_0]).sqrt().view(-1, 1, 1, 1)\n",
    "\n",
    "            # Predict noise\n",
    "            eps_theta = pred\n",
    "\n",
    "            # Compute predicted x_0\n",
    "            pred_x0 = (xt - sqrt_one_minus_alpha_bar_t.detach().cpu() * pred) / sqrt_alpha_t.detach().cpu()\n",
    "#             print(pred_x0.shape)\n",
    "#             print(xt.shape)\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(np.clip(((pred_x0[0].permute(1, 2, 0) + 1) / 2), 0, 1))\n",
    "            \n",
    "            plt.title(\"Predicted previous original-noised\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "#             print((xt.permute(1, 2, 0) + 1) / 2 - (pred.permute(1, 2, 0) + 1) / 2)\n",
    "            loss, current = loss.item(), batch * batch_nbr + len(x0_batch)\n",
    "#             wandb.log({\"step\":  f\"{current:>5d}/{size:>5d}\", \"train_loss\": loss})\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "#             plt.show(x0_batch - pred_noise[0])\n",
    "        \n",
    "print(\"finished\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpling from the learned distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x_t, t):\n",
    "    beta_t = beta[t].view(-1, 1, 1, 1)\n",
    "    sqrt_alpha_t = alpha[t].sqrt().view(-1, 1, 1, 1)\n",
    "    sqrt_one_minus_alpha_bar_t = (1 - alpha_bar[t]).sqrt().view(-1, 1, 1, 1)\n",
    "\n",
    "    # Predict noise\n",
    "    eps_theta = model(x_t, t)\n",
    "\n",
    "    # Compute predicted x_0\n",
    "    pred_x0 = (x_t - sqrt_one_minus_alpha_bar_t * eps_theta) / sqrt_alpha_t\n",
    "\n",
    "    # Compute mean (μ_θ)\n",
    "    mu = (1 / sqrt_alpha_t) * (x_t - beta_t / sqrt_one_minus_alpha_bar_t * eps_theta)\n",
    "\n",
    "    # Sample noise (except for last step)\n",
    "    if t[0] > 0:\n",
    "        noise = torch.randn_like(x_t)\n",
    "    else:\n",
    "        noise = torch.zeros_like(x_t)\n",
    "\n",
    "    x_prev = mu + beta_t.sqrt() * noise\n",
    "    return x_prev.clamp(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, shape=(1, 1, 28, 28)):\n",
    "    x = torch.randn(shape).to(device)\n",
    "    for t_step in reversed(range(T)):\n",
    "        t = torch.full((shape[0],), t_step, dtype=torch.long).to(device)\n",
    "        x = p_sample(model, x, t)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def generate_samples(model, num_samples=48, image_size=img_size):\n",
    "    model.eval()\n",
    "    samples = generate(model, shape=(num_samples, 3, *image_size))\n",
    "    return samples\n",
    "\n",
    "def show_images_grid_rgb(samples, nrow=8, ncol=6):\n",
    "    fig, axes = plt.subplots(ncol, nrow, figsize=(nrow, ncol))\n",
    "    samples = (samples + 1) / 2         # Rescale from [-1, 1] to [0, 1]\n",
    "    samples = samples.clamp(0, 1).cpu() # Ensure valid pixel range\n",
    "    samples = samples.permute(0, 2, 3, 1)  # Convert to (N, H, W, C) for plotting\n",
    "\n",
    "    idx = 0\n",
    "    for row in range(ncol):\n",
    "        for col in range(nrow):\n",
    "            axes[row, col].imshow(samples[idx])\n",
    "            axes[row, col].axis('off')\n",
    "            idx += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "samples = generate_samples(model, num_samples=48, image_size=(32, 32))  # adapt shape to your dataset\n",
    "show_images_grid_rgb(samples, nrow=8, ncol=6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_ddpm(model, n_samples, T, img_size=(3, 32, 32)):\n",
    "    model.eval()\n",
    "    x_t = torch.randn(n_samples, *img_size).to(device)\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        t_tensor = torch.full((n_samples,), t, dtype=torch.long, device=device)\n",
    "\n",
    "        beta_t = beta[t]\n",
    "        alpha_t = alpha[t]\n",
    "        alpha_bar_t = alpha_bar[t]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - alpha_bar_t)\n",
    "        sqrt_recip_alpha = torch.sqrt(1.0 / alpha_t)\n",
    "\n",
    "        eps_theta = model(x_t, t_tensor)\n",
    "\n",
    "        # Predict x0\n",
    "        x0_pred = (x_t - sqrt_one_minus_alpha_bar * eps_theta) / torch.sqrt(alpha_bar_t)\n",
    "\n",
    "        # Predict mean for x_{t-1}\n",
    "        mean = sqrt_recip_alpha * (x_t - beta_t / sqrt_one_minus_alpha_bar * eps_theta)\n",
    "\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            sigma = torch.sqrt(beta_t)\n",
    "            x_t = mean + sigma * noise\n",
    "        else:\n",
    "            x_t = mean  # final prediction\n",
    "\n",
    "    return (x_t + 1) / 2  # rescale from [-1,1] to [0,1]\n",
    "\n",
    "samples = generate_samples(model, num_samples=48, image_size=(32, 32))  # adapt shape to your dataset\n",
    "show_images_grid_rgb(samples, nrow=8, ncol=6)\n",
    "sample_ddpm(model, n_samples, T,img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "correct = \"good-denoising-bad-generalization\"\n",
    "model_name = f\"{correct}--\" + time.strftime(\"%Y-%m-%d_%H-%M-%S\") + \"_VDM_UNET_model.pth\"\n",
    "torch.save(model.state_dict(), MODELS_DIR / model_name)\n",
    "print(\"Saved PyTorch Model State to \" +  model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Saving the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%javascript\n",
    "# IPython.notebook.save_notebook()\n",
    "from ipylab import JupyterFrontEnd\n",
    "app = JupyterFrontEnd()\n",
    "app.commands.execute('docmanager:save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
