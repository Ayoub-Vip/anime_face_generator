% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{ho2020ddpm}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,'' \emph{arXiv preprint arXiv:2006.11239}, 2020.

\bibitem{nichol2021glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, K.~McGrew, and I.~Sutskever, ``Glide: Towards photorealistic image generation and editing with text-guided diffusion models,'' \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem{saharia2022imagen}
C.~Saharia, W.~Chan, S.~Saxena, L.~Li, J.~Whang, E.~Denton, S.~K. Ghasemipour, A.~Kolesnikov, T.~Salimans, J.~Ho, D.~J. Fleet, and Q.~V. Le, ``Imagen: Scaling up diffusion models for text-to-image generation,'' \emph{arXiv preprint arXiv:2205.11487}, 2022.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen, ``Hierarchical text-conditional image generation with clip latents,'' \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{learnopencv2023ddpm}
V.~Singh, ``An in-depth guide to denoising diffusion probabilistic models (ddpm),'' \url{https://learnopencv.com/denoising-diffusion-probabilistic-models/}, 2023, accessed: 2025-08-13.

\bibitem{Note1}
The same resource 2x(Nvidia a5000) allows training Mega on 2 batches, while allowing 6 batches for Giga.

\bibitem{arora2019finegrained}
\BIBentryALTinterwordspacing
S.~Arora, S.~S. Du, W.~Hu, Z.~Li, and R.~Wang, ``Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks,'' in \emph{International Conference on Machine Learning (ICML)}, 2019. [Online]. Available: \url{http://arxiv.org/abs/1901.08584}
\BIBentrySTDinterwordspacing

\bibitem{karras2022elucidating}
\BIBentryALTinterwordspacing
T.~Karras, M.~Aittala, T.~Aila, and S.~Laine, ``Elucidating the design space of diffusion-based generative models,'' \emph{NeurIPS}, 2022. [Online]. Available: \url{https://arxiv.org/abs/2206.00364}
\BIBentrySTDinterwordspacing

\end{thebibliography}
